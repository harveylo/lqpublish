- l1缓存一般分为**指令缓存**和**数据缓存**
- **提升指令缓存命中率**
	- 其实就是提升分支预测命中率，而提升分支预测率的方式就是维持有规律的分支语句
		- 比如对数组进行排序之后，循环中的分支语句将有迹可循
		- 也可以使用``likely``和``unlikely``宏显式告诉编译器分支条件可能的结果
- **提升多核CPU系统的缓存命中率**
	- 考虑把线程绑定到某一个CPU的核心
	- ``linux``提供了``sched_setaffinity``方法，在头文件`<sched.h>`中，用于完成类似功能
		- ``int sched_setaffinity(pid_t pid, size_t cpusetsize, cpu_set_t* mask)``
- **伪共享和避免方式**
	- 一个cache line往往包含一块数据，如果两个CPU核心需要处理同一块cache line中的不同数据而导致频繁的缓存失效，这种情况就叫做**伪共享(False sharing)**
	- **解决方法**：对于**多个线程共享的热点数据**，避免这些数据全部处在同一个cache line中
	- 说白了也就是：[[$red]]==**多线程数据cache line对齐**==
		- ```
		  struct test{
		  	int a;
		      int b;
		  }
		  ```
		- ![](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost3@main/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/CPU%E4%BC%AA%E5%85%B1%E4%BA%AB/struct_ab.png)
		- 上述a，b在同一个cache line中，如果通过填充将其按cache line的大小对齐，就能避免不同的核心同时处理a和b时产生的false sharing
	- Linux下有宏可以用于直接填充，即``__cacheline_aligned_in_smp``
		- 此宏似乎只能在编写内核模块时使用，不能再用户空间程序中使用
		- ```
		  struct test{
		  	int a;
		      int b __cacheline_aligned_in_smp
		  }
		  ```
		- ![](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost3@main/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/CPU%E4%BC%AA%E5%85%B1%E4%BA%AB/struct_ab1.png)
		- 如此一来，a和b就不在同一个cache line中了
- # CPU如何选择线程(调度)
  collapsed:: true
	- ## ``task_struct``结构类
		- Linux内核中，线程和进程都用``task_struct``结构体来表示和管理
			- linux中可以通过``get_current``来获取当前线程的``task_strut``，但是**只能在内核程序中使用**
		- 进程和线程的``task_struct``的区别在于
			- 线程的``task_struct``里部分资源是共享了进程一创建的资源
				- 比如**内存空间，代码段，文件描述符**等
				- 因此Linux中的线程也被称为轻量级线程，其承载的资源比进程``task_struct``的资源少
		- 不管进程是单线程还是多线程，只要开了一个线程，在内核里就相当于多了一个任务，创建了一个``task_struct``，因此在linux中，**内核调度器调度 的对象就是``task_struct``**，一个``task_struct``就对应了一个**任务**
	- ## 优先级
		- **实时任务**：
			- 对系统的响应时间要求很高，需要尽可能快地执行
			- 优先级在``0-99``范围内的任务都算作实时任务
			- [[$red]]==**注**==：优先级值越小，优先级越高
		- **普通任务**
			- 对系统响应时间要求不高
			- 优先级在``100-139``范围内就是普通任务
		- 这里所指的优先级实际是**动态优先级(PR)**，是通过任务的``nice``值动态计算得到的，而`nice`值得取值范围为``-20 ~ 19``，也称**静态优先级(NI)**
	- ## linux的调度类
		- ![](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost3@main/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/CPU%E4%BC%AA%E5%85%B1%E4%BA%AB/%E8%B0%83%E5%BA%A6%E7%B1%BB.png)
		- 其deadline和reatime两个调度类都是应用于实时任务的，这两个调度类总共包含三个策略：
			- ``SCHED_DEADLINE``
				- 按照deadline进行调度
				- 距离当前时间点**最近的属于deadline的任务**会被优先调度
			- ``SCHED_FIFO``
				- 对于**相同优先级**的任务，按先来先服务原则
				- 对于**优先级更高**的任务，可以抢占低优先级任务的资源，即**插队**
			- ``SCHED_RR``
				- 对于**相同优先级**的任务，轮流运行，每个任务都有一定的时间片
					- 使用完时间片的任务会被放到队列尾部
				- **高优先级**的任务可以抢占低优先级任务的时间片
		- fair调度类对应普通任务， 由**CFS(Complete Fair Scheduleing)**调度器管理，分两种调度策略
			- ``SCHED_NORMAL``：普通任务使用的调度策略
			- ``SCHED_BATCH``：后台任务的调度策略，不和终端交互，不影响其他需要**交互**的任务，可以被适当降低优先级
	- ## 完全公平调度
		- 实际编程过程中，遇到的任务基本都是普通任务
			- 而对于普通任务来说，**公平性(fairness)**最重要
		- Linux中实现了基于**CFS**的调度算法，理念是尽量让分配给每个人物的CPU时间保持一致
		- 每一个任务都会被安排一个**虚拟运行时间(vruntime)**
			- 一个任务运行越久，vruntime就会越大，不处于运行状态的任务，vruntime不会变化
			- 在计算vruntime时还会考虑任务的**权重值**，权重值不是nice值也不是优先级，内核中存在一张**nice值和权重值的转换表**，nice级别越低权重值越大。
			- **vruntime += 实际运行时间(``delta_exec``)\* ``NICE_0_LOAD``/权重**
				- ``NOCE_0_LOAD``是一个常量
				- 可以看到，运行了同样的时间之后，**高权重任务的vruntime增量比地权重任务的vruntime增量少**
		- CFS算法在调度时，**[[$red]]==会优先选择vruntime少的任务==**
	- ## CPU运行队列
		- 多任务的数量基本都是**远超CPU核心数**
		- 每个CPU核心都有**三个**自己的**运行队列(Run Queue, rq)**，用于描述在此核心上运行的所有任务
			- ``dl_rq``，deadline运行队列
			- ``rt_rq``，realtime运行队列
			- ``cfs_rq``，CFS运行队列
				- 此队列使用**[[$red]]==红黑树==**描述
				- 按``vruntime``大小排序，最左侧的叶子节点就是下一次会被调度的任务
			- ![](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost3@main/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/CPU%E4%BC%AA%E5%85%B1%E4%BA%AB/CPU%E9%98%9F%E5%88%97.png){:height 370, :width 480}
		- 调度任务时，**考虑顺序为**：``Deadline > Realtime > Fair``
			- 即，先从`dl_rq`里选择任务，然后是``rt_rq``，最后是``cfs_rq``
			- 因此**实时任务总是回避普通任务优先执行**
	- ## 调整优先级
		- 一个任务被启动时的默认优先级是**普通任务**
			- 即，调度类属于``Fair``，由CFS调度器负责管理
		- 调整``nice``值能让优先级高的任务执行更多时间
			- nice值得-20 ~ 19对应到优先级的100 ~ 139
			- 因此nice值不管设置多低，任务仍然是普通任务
			- **在启动任务时**，通过``nice -n <nice> <command>``可以调整启动任务的nice值
			- **已经启动的任务**，通过``renice -<nice> -p <PID>``调整nice值
		- 对于实时性要求高的任务，需要直接改变任务的优先级和调度策略，使用``chrt``命令
			- ``chrt -f <priority> -p <PID>``，如：``chrt -f 1 -p 1998``
- # 软中断
	- 关中断可能会导致**中断丢失**
	- 而对于硬件传达的中断请求，一般都需要关中断，因此这个**关中断的时间需要越短越好**
	- Linux为了压缩关中断时间，**将中断分为了两个阶段**
		- 第一阶段用于**快速处理中断**，一般此阶段会关中断(**[[$red]]==硬中断==**)
			- 主要负责处理**硬件相关**或者**时间敏感**的事件
			- [[$red]]==**直接处理硬件请求**==，耗时短，执行快
			- 硬中断会打断CPU**正在执行**的任务，立即执行中断处理程序
		- 第二阶段用于**延迟处理上一阶段未完成的工作**([[$red]]==**软中断**==)
			- 一般以**内核线程**的方式完成
				- 一般一个CPU核心都对应一个软中断内核线程，名字通常为[ksoftirqd/<CPU编号>]，如``ksoftirqd/0``
			- **[[$red]]==负责完成硬中断剩余工作==**，耗时较长，延迟执行
			- [[$red]]==并不一定是硬中断的下半部分==，一些**内核自义事件**也属于软中断，例如
				- 内核调度
				- RCU锁
	- ## 例子：接收网络包
		- 网卡接收到包后通过**DMA**的方式将接收到的数据写入内存，然后通过**硬件中断**通知CPU，CPU将跳转到中断处理程序的地址来处理此事件
			- 硬中断部分会关网卡中断
		- 然后软中断会介入处理剩下的工作，主要是从内存中找到网络数据，然后按照网络协议逐层解析处理，最后地送给应用程序
	- ## 系统中的软中断
		- 文件``/proc/softirqs``储存了软中断信息和其运行情况
			- 第一列为软中断信息，其后每一列表示此中断在该核心上的运行次数
				- 一般来说，每种中断在各个和欣赏的累计运行次数相差不大
			- 一些中断如下：
				- ``NET_TX``网络发送中断
				- ``NET_RX``网络接收中断
				- ``TIMER``定时中断
				- ``RCU``RCU锁中断
				- ``SCHED``内核调度中断
			- **累计中断次数本身并不重要**，重要的是[[$red]]==**中断次数的增长速率**==
				- 通过``watch -d cat /proc/softirqs``查看中断次数的变化速率
		- 文件``/proc/interrupts``存储了硬中断信息和运行情况
		- 通过``ps -aux | grep softirq``可以查看软中断内核线程
			- 内核线程的名字都是**通过中括号括起来的**，无法获取命令行参数
	- ## 定位导致CPU使用率过高的软中断
		- 使用``top``命令可以查看当前系统的软中断情况
			- 其中``si``列代表的就是软中断所占用的CPU
		- 使用上文提到的``watch -d cat /proc/softirqs``可以查看每种软中断的新增速率
		- 如果发现``NET_RX``网络接受中断次数的新增速率过快，使用``sar -n DEV``，查看网卡的网络包接收速率情况，分析网络包的来源
		- 然后使用``tcpdump``查看热点网卡上网络包的来源地址
			- 如果是非法地址，考虑增添防火墙
			- 如果是合法地址，考虑硬件升级
- # 浮点数
	- 参照IEEE 754标准
	- 由于浮点数只能以近似值储存，一般判定两个**浮点数相等**不会直接用``==``判断，而是通过绝对误差或相对误差来判断是否相等
		- **绝对误差**，如果两个数的绝对值小于某个阈值即判定相等
			- 通常阈值的选择取决于具体的应用场景和精度要求
			- 一般会选择一个很小的数，如``1e-6``
		- **相对误差**，相对误差即两个数的**差除以平均值再取绝对值**