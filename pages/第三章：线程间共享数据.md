- # 共享数据产生的问题
	- 线程间共享数据产生的问题都是修改数据的结果
	- **如果所有的线程对数据都是只读**，则不会有任何问题产生
	- 修改数据产生的问题是，正在发生的修改会破坏一些**不变式(invariant)**
		- 例如，对于一个双向链表，一个不变式是一个节点A的next节点B所存储的back地址一定是A的地址
		- 但是在修改此链表结构的过程中，上述不变式会被打破，修改完成后重新成立
	- ## 竞争状况(Race conditions)
		- 并发中的竞争状况指程序的执行结果(数据状态)取决于**[[$red]]==两个或以上线程相关操作的最终执行顺序==**的情况
		- 竞争状况会使得所有的执行结果都成为可能，而有时这种竞争可能会破坏不变式
		- 一般来说**竞争状况**专指这种会导致不变式破坏的**问题竞争状况**(problematic race condition)
		- C++标准定义了术语**数据竞争**(Data Race)来描述那些由于对单个对象进行并发修改产生的竞争状况
		- 数据竞争往往会导致可怕的**UB**
	- ## 避免问题竞争状况
		- ### 方法一：给数据对象增添保护机制
			- 给数据对象增添保护机制，确保只有正在修改的线程能看到中间状态
			- 对于其他线程来说，修改要么没发生，要么已经完成(原子操作)
			- C++标准库提供了几种机制
		- ### 方法二：lock-free programming
			- 修改数据类的设计，使得修改通过一些列无法分割的改变完成，且每一步都维持了不变式
			- 这种方法叫做**lock-free programming**
			- 比较困难，需要对内存模型的细节有全面的理解
		- ### 方法三：STM(software transactional memory)
			- 对数据结构的更新也需要通过一次**事务(transaction)**提交操作
			- 如果在提交时被操作对象已经被更新过，则从新开始事务
			- 此方法被叫做**STM**
			- 目前还在研究中，C++不提供直接支持，后续不做讨论
- # 使用互斥量(Mutex)保护共享数据
	- C++标准库提供信号量的相关原语
	- 信号量并不是万能的，需要**找准需要保护的对象**，而且可能会导致**死锁**
	- ## 在C++中使用互斥量
		- C++中的信号量类为``std::mutex``
			- 给一个互斥量上锁调用函数``std::lock()``
			- 解锁使用``std::unlock()``
		- 如同一个线程在创建之后必须detach或join一样，一个互斥量在上锁之后也**一定要解锁**
			- 因此以上两个成员函数最好不要直接调用，而是同样使用一个包装类进行RAII处理
			- std提供了一个这样的保护类模板，**std::lock_guard**，在创建时上锁信号量，析构时解锁
				- **C++17**引入了**实参推导**(argument deduction)机制，通过比较简单的模板构造类时可以直接通过实参推导类型参数
				- ``lock_guard<std::mutex> g(m)`` -> ``lock_guard g(m)``
		- C++ 17引入了加强版本的lock_guard，``scoped_lock``，但如果要兼容旧版本的编译器，并不建议使用
		- 为了减少全局变量的使用，互斥量应该和访问函数放在同一个类里，并将互斥量和数据结构都作为私有变量
		- 应该**[[$red]]==保证被保护数据本身不会被返回==**(应该返回拷贝而不是指针和引用等)，也不能把自身数据的实际地址**[[$red]]==传入访问函数==**，因为无法确定传入的指针或引用会被谁使用
	- ## 保护共享数据
		- 想要使用互斥量正确地保护数据，至少需要遵守以下守则：
			- **不要将被保护数据的指针或引用传递到锁的[[$red]]==作用域之外==**，包括作为返回值返回或将其存储在外部可见的内存中
			- **不要将其作为参数传递给[[$red]]==用户提供的函数==**
				- 如果用户提供的参数的形参是左值引用，其就能在锁的作用于之外获取数据的控制权
		- 实际上哪怕做到了上述要求，使用互斥量保护住了数据，数据竞争仍然可能存在
	- ## 注意接口自带的竞争状况
		- 以std::stack为例，其empty函数和size函数在并发环境下都是不可信的，很有可能在做了判断之后，其他进程已经改变了栈中元素的状态和数量，因此非原子性的``if(s.empty()) s.pop();``是不行的
		- 这就是接口自带的竞争状况，哪怕**在栈内部重写逻辑保证了栈中数据的每一次调用都受到一个内部互斥量的保护**，也无法消除这种竞争状况
		- 同样的，``pop,top``之间也存在竞争状况，而且可能产生更严重的后果
		- 有以下几种方式可以消除 这些接口竞争状况，但是**都有一定的的代价**
			- **方法一：**传入引用
				- ``stack.pop(result);``
				- [[$red]]==缺点：==
					- 需要在**调用前**先构造一个对象，某些类型得构造开销非常大
					- 构造一个临时变量往往需要参数用于初始化，传入这些初始化值或者参数很麻烦
					- 某些(尤其是用户自定义)类并不支持拷贝赋值，甚至是拷贝构造，而传引用进去必然是会调用拷贝赋值或拷贝构造函数的
			- **方法二：**使用无异常拷贝函数或移动构造函数
				- 对于一个有返回值的pop()函数来说，唯一不安全的情形就是出现异常的情况
				- 因此如果拷贝构造函数或移动构造函数或两者都不抛出异常，那么用一个变量去接pop函数的返回值应该是不会发生异常的
				- [[$red]]==缺点==：
					- 没有无异常拷贝函数或移动构造函数的类无法适配此方法
			- **方法三**：返回指向弹出值得指针
				- 不直接返回值而是指向弹出元素的指针
				- 使用shared_ptr还能免去程序员手动管理生命周期
				- [[$red]]==缺点==：
					- 内存管理得开销相当大
		- 以上三个方法可以**组合使用**
		- **示例代码：con_stack**
	- ## 死锁
		- 当使用两个或以上互斥量时便有可能产生死锁问题
		- **[[$red]]==复习：==死锁四条件**
			- **互斥**：每个资源只能被一个线程使用
			- **保持**：线程对以获取的资源持续占有不放手
			- **不剥夺**：已经拥有资源占有权的线程不会被剥夺占有权
			- **循环等待**：若干线程形成了循环等待的情况
		- 一个很简单的解决方案是所有线程都要**按照相同的顺序锁互斥量**
			- 但是很多时候互斥量是在保护完全独立的数据，实现根本不能预见到调用顺序
		- 好在C++标准库提供了可以一次性锁多个互斥量的函数**``std::lock()``**
		- 对已经上过锁的mutex再上锁是**[[$red]]==UB==**，除非是用std::recursive_mutex
		- 对于已经使用``std::lock``锁住的互斥量，如果还想使用lock_guard进行管理，则需要配合``std::adopt_lock``(定义在<mutex>中)
		- 使用例：
			- ```
			  friend void swap(X& lhs, X& rhs){
			  	if(&lhs == &rhs) return; //已经锁过的对象不能再被锁，且同一个对象也不需要交换，因此事先做判断
			      std::lock(lhs.m,rhs.m);
			      std::lock_guard<std::mutex> lock0(lhs.m,std::adopt_lock)//std::adopt_lock告知此mutex已经上锁
			      std::lock_guard<std::mutex> lock1(lhs.m,std::adopt_lock)
			      swap(lhs.some_data,rhs.some_data);
			  }
			  ```
		- ### ``std::scoped_lock``
			- **C++17**中引入的新特性
			- 作用和lock_guard相同，但是是一个可变模板(variadic template)
			- 接受一组mutex类型对象作为参数，使用和std::lock相同算法一次性上锁所有给出的互斥量
			- 在析构时解锁所有互斥量
			- ```C++
			  friend void swap(X& lhs, X& rhs){
			  	if(&lhs == &rhs) return;
			      std::scoped_lock guard(lhs.m,rhs.m);
			      swap(lhs.some_data,rhs.some_data);
			  }
			  ```
			- 此处使用了C++17引入的新特性**实参推导**
		- 使用std::lock或std::scoped_lock可以避免很多死锁情况，但如果资源被分开获取，死锁仍然可能存在
	- ## 避免死锁的更多方法
		- 死锁很多时候会以意想不到的方式发生，让两个线程互相对对方调用join就可以造成死锁
		- 总的来说，避免死锁就一句话：[[$red]]==**当另一个线程有可能在等待你时就不要去等待对方**==
		- 以下建议都是描述如何辨别或消除对方在等待你的可能性
		- ### 避免嵌套锁
			- 不要在**已经手握一把锁**的情况下再去请求另一把锁
			- 如果确实要同时上锁多个资源，使用``std::lock``原子性地获取
		- ### 避免在持有锁时调用用户提供的函数
			- 用户提供指不是你自己写的，你无法预料其行为
			- 如果此情况无法避免参看接下来的guideline
		- ### 按固定顺序获取锁
			- 如果不得不获取多把锁且无法一次性获取，则一定要在所有线程里都按照固定顺序获得这些锁
			- 比如对于一个双向链表：
				- 每一个节点都拥有一个互斥量，而若一个线程想访问多个节点或遍历列表，兼顾性能的做法是先锁当前节点，在通过当前节点去锁下一个节点，然后解锁当前节点
				- 那么在遍历时必须要求所有的线程锁和解锁节点的顺序保持一致，不然两个线程对向遍历将有可能产生死锁
		- ### 使用层级锁
			- lock hierachy是上一个建议的特殊案例
			- 将应用分为多个层，定义每一层中的互斥量
			- 如果一个线程持有**低层**的锁 ，则其不被允许获取高层级的锁
			- C++ std不提供层级锁的直接支持，但是可以自己写一个自定义的hierarchical_mutex类
			- 层级锁强制锁按某种顺序进行上锁，因此死锁在层级锁系统中是不可能发生的
			- 另外：只要实现了三个成员函数的类，都可以使用lock_guard进行RAII管理，即：
				- **lock(), unlock(), try_lock()**
			- try_lock函数在调用时如果已经被上锁，则会返回false，而不是阻塞等待
			- 使用**[[$red]]==thread_local==**可以定义线程本地变量 [[thread_local关键字]]
			- **实例代码：hierarchical_mutex**
		- ### 扩展使用到非锁行为
			- 如上所述，任何可能导致循环等待的行为都有可能导致死锁，因此以上建议可以扩展到那些不是上锁的行为
			- 例如，**不要在持有某个锁的情况下等待另一个线程**
			- 线程也可以分出层级，高层及的线程只能等待底层级的线程
				- 可以通过保证所有线程都在启动他们的函数中join来保证这一点
	- ## 使用``std::unique_lock``灵活上锁
		- ``std::unique_lock``提供比``std::lock_guad``更加灵活的锁，可以向其传递额外的参数来确定上锁的行为
			- 第二个参数传入std::adopt_lock，告知已经上锁，不再在constructor上锁，仅作管理
			- 第二个参数传入std::defer_lock标识mutex在constructor中不被上锁，后续用户通过对生成的unique_lock对象调用std::lock或调用对象自身的lock函数对mutex上锁(说明unique_lock类实现了lock,try_lock,unlock三个函数)
		- 但是unique_lock会**占用更多空间**且**运行速度也慢于l**ock_guard
		- **示例代码：unique_lcok**
		- 使用unique_lock对象的owns_lock函数可以查看此对象是否持有传入的mutex
		- 除非需要**转移锁的所有权**或确实需要unique_lock带来的灵活性，在scoped_lock可用的情况下建议使用后者
	- ## 转移mutex的所有权
		- 由于不一定对其包含的mutex拥有所有权，因此mutex的所有权可以通过**move**实例进行转移
		- 这种转移有时是自动完成的，如在函数中return一个实例，其他时候需要显示使用move函数，具体来说：
			- 如果被转移的对象(source)是**左值**，那么需要调用move函数
			- 如果source是右值，会直接转移所有权
		- unique_lock是**可转移的(transferable)**，但是**不可拷贝(not copyable)**
		- 基于此，用户可以**使用一个函数来锁某个mutex，此函数会通过unique_lock将所有权返还给调用者**
		- **代码示例：** unique_lock/get_lock()
		- 一种可转移锁的使用场景是：**gateway对象**
			- 对某些数据的访问需要借助一个门户对象，这种对象就是gateway对象
			- 而若希望保护可以通过gateway对象访问到的数据，gateway对象中可能包含mutex
			- 此时就可以通过一个函数取获得gateway对象，并在返回时摧毁对象并开锁
		- unique_lock的灵活性还体现在既可以 手动unlock也可以让unique_lock对象在析构时自动unlock
	- ## 在何时的粒度上锁
		- 细粒度的锁进保护少量数据，粗粒度的锁保护大量数据
		- 过分使用(没必要的)粗粒度的锁会造成性能方面的大量损耗
		- 切记不要在**持有锁时做长耗时的工作**(例如I/O)，除非真的必要
		- 因此可以提前手动释放(相较于在析构函数中自动释放来说)，并在后续代码中再次调用的unique_lock，其灵活性可以换来性能的提升
		- 因为被访问的数据可能并不需要相同的保护等级，因此“**合适的粒度**”可能根本不存在
- # 另一种保护共享数据的方法
	- 上一小节讨论的问题说明有的问题可能并不能通过**简单的mutex**高效解决
	- 在很多时候，对于数据的并发访问保护**只在其初始化时有必要**，例如此数据在被创建之后是只读的，或者对其的操作暗含了必要的保护措施
	- ## 在初始化时保护共享数据
		- 对于一个**lazy initialization**，且初始化之后不需要进行多线程保护的对象(只在第一次被使用时初始化)，在多线程情况下，如果使用mutex来检查是否已经初始化，则会导致**不必要的线性化**(每次只有一个线程能进行初始化检查)，大幅降低性能
		- 一种***臭名昭著***的解决方案是**double-checked locking**
			- 在第一次初始化检查时不加锁而在第二次检查时加锁
			- ```
			  std::shread_ptr<some_resource> resource_ptr;
			  std::mutex resource_mutex;
			  
			  void double_checked_locking(){
			  	if(!resoutce_ptr){
			      	std::lock_guard<std::mutex> lock(resource_mutex);
			          if(!resource_ptr){
			          	resource_ptr.reset(new some_resource);
			          }
			      }
			      resource_ptr->do_something();
			  }
			  ```
			- 此方法[[$red]]==**之所以臭名昭著**==是因为第一次检查并没有同步，因此有可能出现以下状况：
				- 线程1进入函数发现对象没有初始化，因此开始初始化
				- 线程2进入函数，此时线程1对于对象的初始化可能刚进行到途中，此时指针已经不为空，但是线程1对于对象的初始化没有完全完成仍然在写对象
				- 线程2直接调用对象的函数进行操作，和线程1的操作出现了冲突，可能损坏数据，也有可能拿到不完整的数据
		- C++标准库提供了对于这种场景的解决方案：**``std::once_flag``**和**`std::call_once`**
			- ```
			  class X{
			  private: 
			  	connection info connection_details;
			  	connection_handle connection;
			      std::once_flag connection_flag;
			      void open connection(){
			      	connection = connection_manager.open(connection_details);
			      }
			  public:
			  	X(const connection_info& connnection_details):connection_details(connection_details){}
			      void send_data(const data_packet& data){
			      	std::call_once(connection_flag,&X::open_connection,this);//调用类函数需要传入一个类对象指针
			          conncection.send_data(data);
			      }
			      data_packet receive_data(){
			      	std::call_once(connection_flag,&X::open_connection,this);
			          return connection.receive_data();
			      }
			  };
			  ```
			- **注意：once_flag是不可复制，仅可移动的**
			- [[$red]]==**另**==：在C++11之后，**静态变量的初始化是线程安全的**
	- ## 保护很少更新的数据结构
		- 仅保护初始化其实是保护很少更新及数据结构的一个特例
		- 我们希望有如下**读-写互斥(reader-writer mutex)**的特性：
			- 写线程在更新时能锁定数据，任何其他线程都无法访问
			- 读线程可以并发访问数据
		- 以上特性普通的mutex无法完成，C++17提供了两种读写互斥量：**``std::shared_mutex``**和**``std::shared_timed_mutex``**，c++14只支持后者，C++11两者均不支持
			- C++11若希望使用读写互斥量，需要使用Boost library
			- 后者提供额外的操作，前者在牺牲这些操作的情况下在部分平台上可能性能更好
		- 以上提到的性能提升取决于平台特性和读者，写者线程的相关工作量，不可视为万灵药
		- 在可以将shared_mutex作为参数传递给shared_lock，进行共享上锁
		- 当需要独占shared_mutex时，调用一般的lock即可独占上锁
		- 两种上锁行为的区别：
			- 共享锁可以上任意次
			- 试图上独占锁时，会等所有已经持有共享锁的线程都开锁之后才会上独占锁
			- 在独占锁持有期间，任何上锁请求都会pending直到持有独占锁的线程开锁
	- ## 递归锁(recursive Locking)
		- 不同于一般的mutex，``std::recursive_mutex``**[[$red]]==不会在重复上锁时出现UB==**
		- **上锁多少次，就要解锁多少次**
			- 正确使用``std::unique_lock``和``std::lock_guard``会自动处理好上锁解锁的问题