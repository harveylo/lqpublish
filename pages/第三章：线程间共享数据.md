- # 共享数据产生的问题
	- 线程间共享数据产生的问题都是修改数据的结果
	- **如果所有的线程对数据都是只读**，则不会有任何问题产生
	- 修改数据产生的问题是，正在发生的修改会破坏一些**不变式(invariant)**
		- 例如，对于一个双向链表，一个不变式是一个节点A的next节点B所存储的back地址一定是A的地址
		- 但是在修改此链表结构的过程中，上述不变式会被打破，修改完成后重新成立
	- ## 竞争状况(Race conditions)
		- 并发中的竞争状况指程序的执行结果(数据状态)取决于**[[$red]]==两个或以上线程相关操作的最终执行顺序==**的情况
		- 竞争状况会使得所有的执行结果都成为可能，而有时这种竞争可能会破坏不变式
		- 一般来说**竞争状况**专指这种会导致不变式破坏的**问题竞争状况**(problematic race condition)
		- C++标准定义了术语**数据竞争**(Data Race)来描述那些由于对单个对象进行并发修改产生的竞争状况
		- 数据竞争往往会导致可怕的**UB**
	- ## 避免问题竞争状况
		- ### 方法一：给数据对象增添保护机制
			- 给数据对象增添保护机制，确保只有正在修改的线程能看到中间状态
			- 对于其他线程来说，修改要么没发生，要么已经完成(原子操作)
			- C++标准库提供了几种机制
		- ### 方法二：lock-free programming
			- 修改数据类的设计，使得修改通过一些列无法分割的改变完成，且每一步都维持了不变式
			- 这种方法叫做**lock-free programming**
			- 比较困难，需要对内存模型的细节有全面的理解
		- ### 方法三：STM(software transactional memory)
			- 对数据结构的更新也需要通过一次**事务(transaction)**提交操作
			- 如果在提交时被操作对象已经被更新过，则从新开始事务
			- 此方法被叫做**STM**
			- 目前还在研究中，C++不提供直接支持，后续不做讨论
- # 使用互斥量(Mutex)保护共享数据
	- C++标准库提供信号量的相关原语
	- 信号量并不是万能的，需要**找准需要保护的对象**，而且可能会导致**死锁**
	- ## 在C++中使用互斥量
		- C++中的信号量类为``std::mutex``
			- 给一个互斥量上锁调用函数``std::lock()``
			- 解锁使用``std::unlock()``
		- 如同一个线程在创建之后必须detach或join一样，一个互斥量在上锁之后也**一定要解锁**
			- 因此以上两个成员函数最好不要直接调用，而是同样使用一个包装类进行RAII处理
			- std提供了一个这样的保护类模板，**std::lock_guard**，在创建时上锁信号量，析构时解锁
				- **C++17**引入了**实参推导**(argument deduction)机制，通过比较简单的模板构造类时可以直接通过实参推导类型参数
				- ``lock_guard<std::mutex> g(m)`` -> ``lock_guard g(m)``
		- C++ 17引入了加强版本的lock_guard，``scoped_lock``，但如果要兼容旧版本的编译器，并不建议使用
		- 为了减少全局变量的使用，互斥量应该和访问函数放在同一个类里，并将互斥量和数据结构都作为私有变量
		- 应该**[[$red]]==保证被保护数据本身不会被返回==**(应该返回拷贝而不是指针和引用等)，也不能把自身数据的实际地址**[[$red]]==传入访问函数==**，因为无法确定传入的指针或引用会被谁使用
	- ## 保护共享数据
		- 想要使用互斥量正确地保护数据，至少需要遵守以下守则：
			- **不要将被保护数据的指针或引用传递到锁的[[$red]]==作用域之外==**，包括作为返回值返回或将其存储在外部可见的内存中
			- **不要将其作为参数传递给[[$red]]==用户提供的函数==**
				- 如果用户提供的参数的形参是左值引用，其就能在锁的作用于之外获取数据的控制权
		- 实际上哪怕做到了上述要求，使用互斥量保护住了数据，数据竞争仍然可能存在
	- ## 注意接口自带的竞争状况
		- 以std::stack为例，其empty函数和size函数在并发环境下都是不可信的，很有可能在做了判断之后，其他进程已经改变了栈中元素的状态和数量，因此非原子性的``if(s.empty()) s.pop();``是不行的
		- 这就是接口自带的竞争状况，哪怕**在栈内部重写逻辑保证了栈中数据的每一次调用都受到一个内部互斥量的保护**，也无法消除这种竞争状况
		- 同样的，``pop,top``之间也存在竞争状况，而且可能产生更严重的后果
		- 有以下几种方式可以消除 这些接口竞争状况，但是**都有一定的的代价**
			- **方法一：**传入引用
				- ``stack.pop(result);``
				- [[$red]]==缺点：==
					- 需要在**调用前**先构造一个对象，某些类型得构造开销非常大
					- 构造一个临时变量往往需要参数用于初始化，传入这些初始化值或者参数很麻烦
					- 某些(尤其是用户自定义)类并不支持拷贝赋值，甚至是拷贝构造，而传引用进去必然是会调用拷贝赋值或拷贝构造函数的
			- **方法二：**使用无异常拷贝函数或移动构造函数
				- 对于一个有返回值的pop()函数来说，唯一不安全的情形就是出现异常的情况
				- 因此如果拷贝构造函数或移动构造函数或两者都不抛出异常，那么用一个变量去接pop函数的返回值应该是不会发生异常的
				- [[$red]]==缺点==：
					- 没有无异常拷贝函数或移动构造函数的类无法适配此方法
			- **方法三**：返回指向弹出值得指针
				- 不直接返回值而是指向弹出元素的指针
				- 使用shared_ptr还能免去程序员手动管理生命周期
				- [[$red]]==缺点==：
					- 内存管理得开销相当大
		- 以上三个方法可以**组合使用**
	- ## 死锁
		- 当使用两个或以上互斥量时便有可能产生死锁问题
		- **[[$red]]==复习：==死锁四条件**
			- **互斥**：每个资源只能被一个线程使用
			- **保持**：线程对以获取的资源持续占有不放手
			- **不剥夺**：已经拥有资源占有权的线程不会被剥夺占有权
			- **循环等待**：若干线程形成了循环等待的情况
		- 一个很简单的解决方案是所有线程都要**按照相同的顺序锁互斥量**
			- 但是很多时候互斥量是在保护完全独立的数据，实现根本不能预见到调用顺序
		- 好在C++标准库提供了可以一次性锁多个互斥量的函数**``std::lock()``**
		- 对已经上过锁的mutex再上锁是**[[$red]]==UB==**，除非是用std::recursive_mutex
		- 对于已经使用``std::lock``锁住的互斥量，如果还想使用lock_guard进行管理，则需要配合``std::adopt_lock``(定义在<mutex>中)
		- 使用例：
			- ```
			  friend void swap(X& lhs, X& rhs){
			  	if(&lhs == &rhs) return; //已经锁过的对象不能再被锁，且同一个对象也不需要交换，因此事先做判断
			      std::lock(lhs.m,rhs.m);
			      std::lock_guard<std::mutex> lock0(lhs.m,std::adopt_lock)//std::adopt_lock告知此mutex已经上锁
			      std::lock_guard<std::mutex> lock1(lhs.m,std::adopt_lock)
			      swap(lhs.some_data,rhs.some_data);
			  }
			  ```
		- ### ``std::scoped_lock``
			- **C++17**中引入的新特性
			- 作用和lock_guard相同，但是是一个可变模板(variadic template)
			- 接受一组mutex类型对象作为参数，使用和std::lock相同算法一次性上锁所有给出的互斥量
			- 在析构时解锁所有互斥量
			- ```C++
			  friend void swap(X& lhs, X& rhs){
			  	if(&lhs == &rhs) return;
			      std::scoped_lock guard(lhs.m,rhs.m);
			      swap(lhs.some_data,rhs.some_data);
			  }
			  ```
			- 此处使用了C++17引入的新特性**实参推导**
		- 使用std::lock或std::scoped_lock可以避免很多死锁情况，但如果资源被分开获取，死锁仍然可能存在
	- ## 避免死锁的更多方法
		-